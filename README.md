# Infero
An easy to use LLM inference library powered by [llama.cpp](https://github.com/ggerganov/llama.cpp) with CUDA for GPU acceleration.
